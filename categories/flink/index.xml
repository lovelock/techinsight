<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Flink on Tech In Sight</title><link>https://techinsight.pages.dev/categories/flink/</link><description>Recent content in Flink on Tech In Sight</description><generator>Hugo -- gohugo.io</generator><language>zh-cn</language><lastBuildDate>Tue, 24 Feb 2026 17:24:49 +0800</lastBuildDate><atom:link href="https://techinsight.pages.dev/categories/flink/index.xml" rel="self" type="application/rss+xml"/><item><title>深度解构 Flink：2000 并行度下的性能、延迟与一致性博弈</title><link>https://techinsight.pages.dev/p/%E6%B7%B1%E5%BA%A6%E8%A7%A3%E6%9E%84-flink2000-%E5%B9%B6%E8%A1%8C%E5%BA%A6%E4%B8%8B%E7%9A%84%E6%80%A7%E8%83%BD%E5%BB%B6%E8%BF%9F%E4%B8%8E%E4%B8%80%E8%87%B4%E6%80%A7%E5%8D%9A%E5%BC%88/</link><pubDate>Tue, 24 Feb 2026 17:24:49 +0800</pubDate><guid>https://techinsight.pages.dev/p/%E6%B7%B1%E5%BA%A6%E8%A7%A3%E6%9E%84-flink2000-%E5%B9%B6%E8%A1%8C%E5%BA%A6%E4%B8%8B%E7%9A%84%E6%80%A7%E8%83%BD%E5%BB%B6%E8%BF%9F%E4%B8%8E%E4%B8%80%E8%87%B4%E6%80%A7%E5%8D%9A%E5%BC%88/</guid><description>&lt;h3 id="引言"&gt;&lt;a href="#%e5%bc%95%e8%a8%80" class="header-anchor"&gt;&lt;/a&gt;引言
&lt;/h3&gt;&lt;p&gt;在流处理领域，Apache Flink 以其强一致性（Exactly-Once）闻名。但在并行度高达 2000+ 的大规模工业场景中，盲目追求极致一致性会导致吞吐量骤降、作业“假死”。本文将结合生产一线调优经验，深度探讨 Flink 在检查点（Checkpoint）、延迟表现及故障恢复中的权衡细节。&lt;/p&gt;
&lt;hr /&gt;
&lt;h2 id="一-性能死结2000-并行度下的全连接阻塞"&gt;&lt;a href="#%e4%b8%80-%e6%80%a7%e8%83%bd%e6%ad%bb%e7%bb%932000-%e5%b9%b6%e8%a1%8c%e5%ba%a6%e4%b8%8b%e7%9a%84%e5%85%a8%e8%bf%9e%e6%8e%a5%e9%98%bb%e5%a1%9e" class="header-anchor"&gt;&lt;/a&gt;一、 性能死结：2000 并行度下的“全连接阻塞”
&lt;/h2&gt;&lt;p&gt;当并行度从 40 扩展到 2000 时，性能损耗并非线性增加，而是呈几何倍数增长，其核心原因在于 &lt;strong&gt;Shuffle 网络栈与屏障对齐（Barrier Alignment）&lt;/strong&gt; 的耦合。&lt;/p&gt;
&lt;h3 id="1-全连接all-to-all的网络压力"&gt;&lt;a href="#1-%e5%85%a8%e8%bf%9e%e6%8e%a5all-to-all%e7%9a%84%e7%bd%91%e7%bb%9c%e5%8e%8b%e5%8a%9b" class="header-anchor"&gt;&lt;/a&gt;1. 全连接（All-to-All）的网络压力
&lt;/h3&gt;&lt;p&gt;在使用 &lt;code&gt;keyBy&lt;/code&gt; 或 &lt;code&gt;rebalance&lt;/code&gt; 时，Flink 会构建一个 $2000 \times 2000$ 的逻辑网络连接。这意味着每个下游 Task 都在同时处理来自 2000 个上游通道的输入。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Exactly-Once 的代价：&lt;/strong&gt; 在 EO 模式下，算子必须集齐全部 2000 个上游的 Barrier 才能触发快照。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;木桶效应的极限：&lt;/strong&gt; 只要 2000 个并行 Subtask 中有 &lt;strong&gt;1 个&lt;/strong&gt; 发生毫秒级的 GC 或网络抖动，下游算子的所有通道都会因等待对齐而被迫缓存数据到内存（Buffer 积压）。&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id="2-架构降级走向-at-least-once"&gt;&lt;a href="#2-%e6%9e%b6%e6%9e%84%e9%99%8d%e7%ba%a7%e8%b5%b0%e5%90%91-at-least-once" class="header-anchor"&gt;&lt;/a&gt;2. 架构降级：走向 At-Least-Once
&lt;/h3&gt;&lt;p&gt;切换至 &lt;strong&gt;At-Least-Once (ALO)&lt;/strong&gt; 后，Flink 内部发生了本质变化：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;首位触发机制：&lt;/strong&gt; 算子不再等待 2000 个 Barrier 全数到齐，而是收到 &lt;strong&gt;第 1 个&lt;/strong&gt; Barrier 立即开始异步快照。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;零阻塞处理：&lt;/strong&gt; 快照期间，算子照常消费所有通道的数据，彻底消除了由于“等待对齐”导致的 CPU 空转。&lt;/li&gt;
&lt;/ul&gt;
&lt;hr /&gt;
&lt;h2 id="二-监控幻象锯齿状-lag-与位移提交细节"&gt;&lt;a href="#%e4%ba%8c-%e7%9b%91%e6%8e%a7%e5%b9%bb%e8%b1%a1%e9%94%af%e9%bd%bf%e7%8a%b6-lag-%e4%b8%8e%e4%bd%8d%e7%a7%bb%e6%8f%90%e4%ba%a4%e7%bb%86%e8%8a%82" class="header-anchor"&gt;&lt;/a&gt;二、 监控幻象：锯齿状 Lag 与位移提交细节
&lt;/h2&gt;&lt;p&gt;在监控面板上看到的 15s 周期性 Lag 锯齿，本质上是 &lt;strong&gt;异步快照机制与 Kafka Offset 提交逻辑&lt;/strong&gt; 的时间差。&lt;/p&gt;
&lt;h3 id="1-提交触发的链路细节"&gt;&lt;a href="#1-%e6%8f%90%e4%ba%a4%e8%a7%a6%e5%8f%91%e7%9a%84%e9%93%be%e8%b7%af%e7%bb%86%e8%8a%82" class="header-anchor"&gt;&lt;/a&gt;1. 提交触发的链路细节
&lt;/h3&gt;&lt;p&gt;Flink 对 Kafka 位移的提交严格遵循以下序列：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;Barrier 抵达：&lt;/strong&gt; Source 算子记录当前各 Partition 的 Offset。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;异步上传：&lt;/strong&gt; 各个 Task 将状态（含 Offset）写入 HDFS/S3。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;JobManager 确认：&lt;/strong&gt; 只有当 &lt;strong&gt;所有 2000 个 Task&lt;/strong&gt; 都汇报 CP 成功后，JM 才会向 Source 发出 &lt;code&gt;notifyCheckpointComplete&lt;/code&gt; 指令。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Kafka Commit：&lt;/strong&gt; 收到指令后，Source 才会真正执行 &lt;code&gt;consumer.commitOffsets()&lt;/code&gt;。&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 id="2-为什么会有-15s-的锯齿"&gt;&lt;a href="#2-%e4%b8%ba%e4%bb%80%e4%b9%88%e4%bc%9a%e6%9c%89-15s-%e7%9a%84%e9%94%af%e9%bd%bf" class="header-anchor"&gt;&lt;/a&gt;2. 为什么会有 15s 的锯齿？
&lt;/h3&gt;&lt;p&gt;因为 Kafka Broker 侧的监控（如 CMAK）只能看到第 4 步发生的物理提交。如果你的 CP 间隔是 15s，即便数据在第 1s 就被 Flink 处理完了，Kafka 监控也会显示 Lag 持续增长了 14s，直到下一轮提交。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;深度指标：&lt;/strong&gt; 应关注 &lt;code&gt;currentFetchEventTimeLag&lt;/code&gt;，它记录的是数据被读入 Flink 内存的即时延迟，而非汇报延迟。&lt;/li&gt;
&lt;/ul&gt;
&lt;hr /&gt;
&lt;h2 id="三-状态存续内存攒批与故障恢复的权衡"&gt;&lt;a href="#%e4%b8%89-%e7%8a%b6%e6%80%81%e5%ad%98%e7%bb%ad%e5%86%85%e5%ad%98%e6%94%92%e6%89%b9%e4%b8%8e%e6%95%85%e9%9a%9c%e6%81%a2%e5%a4%8d%e7%9a%84%e6%9d%83%e8%a1%a1" class="header-anchor"&gt;&lt;/a&gt;三、 状态存续：内存攒批与故障恢复的权衡
&lt;/h2&gt;&lt;p&gt;为了控制下游 MySQL 或 Kafka 的写入频率，我们通常在 &lt;code&gt;processElement&lt;/code&gt; 中实现 1s/100条 的攒批逻辑。但 2000 并行度下，如何确保这批数据在崩溃时不丢失？&lt;/p&gt;
&lt;h3 id="1-托管状态liststate-的底层保证"&gt;&lt;a href="#1-%e6%89%98%e7%ae%a1%e7%8a%b6%e6%80%81liststate-%e7%9a%84%e5%ba%95%e5%b1%82%e4%bf%9d%e8%af%81" class="header-anchor"&gt;&lt;/a&gt;1. 托管状态：ListState 的底层保证
&lt;/h3&gt;&lt;p&gt;直接使用 Java &lt;code&gt;ArrayList&lt;/code&gt; 会导致 Failover 时数据丢失。正确的姿势是实现 &lt;code&gt;CheckpointedFunction&lt;/code&gt;：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;快照阶段（snapshotState）：&lt;/strong&gt; 将内存 &lt;code&gt;ArrayList&lt;/code&gt; 的数据 Copy 到 Flink 托管的 &lt;code&gt;ListState&lt;/code&gt;。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;恢复阶段（initializeState）：&lt;/strong&gt; 如果作业重启，Flink 会自动从检查点拉回这部分数据，重新填充内存列表。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;状态分布：&lt;/strong&gt; 在 2000 并行度下，这种状态是典型的 &lt;strong&gt;Operator State&lt;/strong&gt;，它不依赖 &lt;code&gt;keyBy&lt;/code&gt;，在扩缩容时会均匀地在 Subtask 间重新分配。&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id="2-恢复一致性分析"&gt;&lt;a href="#2-%e6%81%a2%e5%a4%8d%e4%b8%80%e8%87%b4%e6%80%a7%e5%88%86%e6%9e%90" class="header-anchor"&gt;&lt;/a&gt;2. 恢复一致性分析
&lt;/h3&gt;&lt;p&gt;在 ALO 模式下，故障恢复后的行为特征如下：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;不丢数据：&lt;/strong&gt; 依靠 &lt;code&gt;ListState&lt;/code&gt; 找回了快照时刻积压在内存的 100 条数据。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;数据重复：&lt;/strong&gt; 既然是 ALO，Source 会回溯到上一个快照的 Offset。那些在快照触发后、崩溃发生前已经发往下游的数据，会被再次处理。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;对策：&lt;/strong&gt; 下游 Sink（如 MySQL）需通过 &lt;code&gt;INSERT ... ON DUPLICATE KEY UPDATE&lt;/code&gt; 实现幂等，从而在 ALO 的高性能基础上获得最终一致性。&lt;/li&gt;
&lt;/ul&gt;
&lt;hr /&gt;
&lt;h2 id="四-2000-并行度下的最佳实践建议"&gt;&lt;a href="#%e5%9b%9b-2000-%e5%b9%b6%e8%a1%8c%e5%ba%a6%e4%b8%8b%e7%9a%84%e6%9c%80%e4%bd%b3%e5%ae%9e%e8%b7%b5%e5%bb%ba%e8%ae%ae" class="header-anchor"&gt;&lt;/a&gt;四、 2000 并行度下的最佳实践建议
&lt;/h2&gt;&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;配置调优：&lt;/strong&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;CheckpointingMode.AT_LEAST_ONCE&lt;/code&gt;（必选）。&lt;/li&gt;
&lt;li&gt;&lt;code&gt;setMinPauseBetweenCheckpoints(10s)&lt;/code&gt;：确保在 2000 个并行任务写入 IO 后，给 HDFS 和 CPU 留出恢复时间。&lt;/li&gt;
&lt;/ul&gt;
&lt;ol start="2"&gt;
&lt;li&gt;&lt;strong&gt;分发策略：&lt;/strong&gt; 弃用 &lt;code&gt;keyBy&lt;/code&gt; 转向 &lt;code&gt;rebalance()&lt;/code&gt;，消除哈希计算开销，解决大 Key 倾斜。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Sink 优化：&lt;/strong&gt; Kafka Sink 应调整 &lt;code&gt;linger.ms&lt;/code&gt; 和 &lt;code&gt;batch.size&lt;/code&gt;，让客户端在物理层攒批，而非仅依靠 Flink 算子。&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 id="结语"&gt;&lt;a href="#%e7%bb%93%e8%af%ad" class="header-anchor"&gt;&lt;/a&gt;结语
&lt;/h3&gt;&lt;p&gt;分布式系统的优化是一场关于“透明性”的博弈。通过舍弃昂贵的“强一致性屏障”，利用托管状态保证“不丢”，并配合下游幂等实现“不乱”，我们才能在 2000 并行度的重载下，构建出既实时又稳定的流处理系统。&lt;/p&gt;</description></item><item><title>Flink的新特性——Unaligned Checkpoints</title><link>https://techinsight.pages.dev/p/flink%E7%9A%84%E6%96%B0%E7%89%B9%E6%80%A7unaligned-checkpoints/</link><pubDate>Thu, 04 Feb 2021 22:55:48 +0800</pubDate><guid>https://techinsight.pages.dev/p/flink%E7%9A%84%E6%96%B0%E7%89%B9%E6%80%A7unaligned-checkpoints/</guid><description>&lt;p&gt;终于看到Flink承认自己在背压高的时候Checkpoint慢的事实了。甚至详细介绍的文章都才只写了第一篇。&lt;/p&gt;
&lt;p&gt;关于&lt;strong&gt;Unaligned Checkpoint&lt;/strong&gt;（非对齐检查点）的详细介绍官网上已经有很多了，前段时间刚发布了系列文章的第一篇&lt;a class="link" href="https://flink.apache.org/2020/10/15/from-aligned-to-unaligned-checkpoints-part-1.html" target="_blank" rel="noopener"
&gt;&lt;br /&gt;
From Aligned to Unaligned Checkpoints - Part 1: Checkpoints, Alignment, and Backpressure&lt;/a&gt;。其中明确提到了以下内容&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Despite all these great properties, Flink’s checkpointing method has an Achilles Heel: the speed of a completed checkpoint is determined by the speed at which data flows through the application. When the application backpressures, the processing of checkpoints is backpressured as well (Appendix 1 recaps what is backpressure and why it can be a good thing). In such cases, checkpoints may take longer to complete or even time out completely.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;之前一直觉得Flink在流式计算领域是神一样的存在，没有缺点。但实际用了之后才发现就这一点就够喝一壶了。所谓流式数据其实就是（没有边界的）消息队列了，那么消息队列的一大用途就是&lt;strong&gt;削峰填谷&lt;/strong&gt;，好了，这里面的_消峰_就是在流量高峰的时候能以其极高的性能扛住压力，保证在数据压力降下来之前数据的不丢失。没错，Kafka在这里扛住了，但Flink掉链子了。&lt;/p&gt;
&lt;p&gt;所谓背压（有的叫反压，原文Back Pressure），对于数据源（DataSource）来说，其实就是下游的消费能力不足，导致上游数据无法完成整个流程（从数据源流入数据汇DataSink），具体到Kafka的这个场景来说就是业务处理的流程慢。&lt;/p&gt;
&lt;p&gt;正常来说，我们是希望当数据流量大的时候系统能加快处理，比如设计处理能力是1000tps，实际平时只有300tps，那么当流量上来时我们是期望它能按设计处理能力消费数据，让数据高峰尽快消散的，但实际情况是当数据量增大时，处理能力从300tps变成了2tps。&lt;/p&gt;
&lt;p&gt;是的，堆积越多处理越慢。反过来处理越慢，堆积越快。陷入了死循环。&lt;/p&gt;
&lt;p&gt;上面文章里也说了，导致这个结果的原因并不是真的是业务代码处理的慢，确确实实就是在背压出现时，Checkpoint变慢了。所以在新版本推出了非对齐检查点模式。&lt;/p&gt;
&lt;p&gt;这里有一个Inflight-data的概念，我理解就是新的检查点方式是把每个TaskManager中处理的数据都快照下来了，也不用管水位线什么的，直接搞起，完成一个删除上一个，带来的效果就是完成检查点的速度和背压没有太直接的关系了，实际的使用也验证了这一点。但和预期还是有稍稍的不同，从Kafka监控来看，按照之前对齐检查点方式，每个检查点完成后立即就能看到监控上的消费波峰，但非对齐检查点的完成和波峰就没有直接关系，不过它起码比对齐检查点好在不会在数据流量高峰到来时全部超时，导致系统瘫痪。&lt;/p&gt;
&lt;p&gt;带来的好处直观而明显，但不方便之处也是有的。&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;对检查点存储后端的压力会非常大。&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;之前每个检查点大小是24K左右，而改成新的方式后就达到了200MB左右，对IO的压力增加可想而知，不过由于我们用的是rocksdb后端，所以这个压力可以承受。&lt;/p&gt;
&lt;ol start="2"&gt;
&lt;li&gt;这种情况下自动创建的检查点不能用来扩容/缩容。&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;由于没有对齐，就没办法做内部的rescale，重启前后的TaskManager数量必须一致。但好在可以通过人工生成SavePoint的方式来创建一个完整的保存点，用保存点保证重启过程的数据不丢失。&lt;/p&gt;
&lt;h2 id="总结"&gt;&lt;a href="#%e6%80%bb%e7%bb%93" class="header-anchor"&gt;&lt;/a&gt;总结
&lt;/h2&gt;&lt;p&gt;总之Flink的这个新功能还是非常有用的，在使用这个功能之前数据量增大的时候只能祈祷它不超时，然而总是事与愿违。&lt;br /&gt;
看文档说后面的目标是把非对齐检查点作为默认的检查点模式，从目前看还有很长的路要走。&lt;/p&gt;</description></item></channel></rss>